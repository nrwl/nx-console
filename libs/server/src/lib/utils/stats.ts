import { readFileSync } from 'fs';
import { gzipSync } from 'zlib';
import { join } from 'path';

import { SPECIAL_SOURCE_FILE_MAPPINGS } from './stats.constants';

// @ts-ignore
const exploreSourceMap = __non_webpack_require__('source-map-explorer');

export interface Chunk {
  name: string;
  file: string;
  size: string;
  type: string;
}

interface FileSize {
  gzipped: number;
  parsed: number;
}

interface FileSizeGetter {
  read: (path: string, cwd?: string) => FileSize;
}

class FileSystemFileSizeGetter implements FileSizeGetter {
  read(asset: string, cwd?: string) {
    const filePath = cwd ? join(cwd, '/', asset) : asset;
    const file = readFileSync(filePath);
    return {
      parsed: file.length,
      gzipped: gzipSync(file).length
    };
  }
}

class FileNameNormalizer {
  cwdPrefixRegexp: RegExp;

  constructor(cwd: string) {
    this.cwdPrefixRegexp = new RegExp(
      `^[\/]*(${cwd.toLowerCase().replace(/^\//, '')})?[\/]*(.*)`
    );
  }

  normalize(s: string) {
    const match = this.cwdPrefixRegexp.exec(s.toLowerCase());
    const file = match ? match[2] : s.toLowerCase();
    for (const k of Object.keys(SPECIAL_SOURCE_FILE_MAPPINGS)) {
      if (file.startsWith(k)) {
        return file.replace(k, SPECIAL_SOURCE_FILE_MAPPINGS[k]);
      }
    }
    return file;
  }
}

export function parseStats(
  stats: any,
  cwd: string,
  fileSizeGetter: FileSizeGetter = new FileSystemFileSizeGetter()
) {
  const outputPath = stats.outputPath;
  // grouped by index as id since webpack ids are sequential numbers
  const modulesByChunkId: { [key: string]: ModuleData[] } = {};
  const summary = {
    assets: createSizeData(),
    modules: 0,
    dependencies: 0
  };
  const assets: any[] = [];
  const chunks: ChunkData[] = [];

  stats.assets.forEach((asset: any) => {
    // Ignore the stats.json file generated by webpack.
    if (asset.name === 'stats.json') {
      return;
    }
    // Ignore sourcemaps.
    if (asset.name.endsWith('.map')) {
      return;
    }
    const sizes = fileSizeGetter.read(asset.name, outputPath);
    summary.assets.parsed += sizes.parsed;
    summary.assets.gzipped += sizes.gzipped;
    assets.push({
      name: asset.name,
      chunkNames: asset.chunkNames,
      sizes: sizes
    });
  });

  // Windows path uses '\', but webpack and sourcemap contain '/'.
  const normalizedCwd = cwd.replace(/\\/g, '/');
  const fileNormalizer = new FileNameNormalizer(normalizedCwd);

  stats.chunks.forEach((chunk: any) => {
    const chunkData = getChunkData(chunk);
    const chunkSizes = fileSizeGetter.read(chunkData.file, outputPath);
    const modules: ModuleData[] = [];

    chunkData.sizes.parsed = chunkSizes.parsed;
    chunkData.sizes.gzipped = chunkSizes.gzipped;
    chunks.push(chunkData);

    try {
      const sourceMapData = exploreSourceMap(join(outputPath, chunkData.file));

      Object.keys(sourceMapData.files).forEach(_file => {
        const size = sourceMapData.files[_file];
        summary.modules += size;

        if (_file === '<unmapped>') {
          modules.push({
            size,
            file: _file,
            isDep: false
          });
        } else {
          const file = fileNormalizer.normalize(_file);
          const isDep = /node_modules/.test(file);

          if (isDep) {
            summary.dependencies += size;
          }

          modules.push({
            size,
            file,
            isDep
          });
        }
      });
    } catch (e) {
      // If we fail to parse sourcemaps it either does not exist, or explorer cannot parse it.
      // Return the chunk as the only module.
      summary.modules += chunkData.sizes.parsed;
      modules.push({
        size: chunkData.sizes.parsed,
        file: chunkData.file,
        isDep: false
      });
    }

    modulesByChunkId[chunkData.id] = modules;
  });

  return {
    assets,
    chunks,
    errors: stats.errors,
    warnings: stats.warnings,
    modulesByChunkId,
    summary
  };
}

export function calculateStatsFromChunks(cs: Chunk[]) {
  const assets: any[] = [];
  const summary = {
    assets: createSizeData(),
    modules: 0,
    dependencies: 0
  };
  const chunks: ChunkData[] = [];

  cs.forEach((c, idx) => {
    const chunkData = {
      id: String(idx),
      file: c.file,
      name: c.name,
      sizes: createSizeData()
    };
    const size = parseSizeFromBuildOutput(c.size);

    chunkData.sizes.parsed = size;
    summary.assets.parsed += size;
    summary.modules += size;

    chunks.push(chunkData);
    assets.push({
      name: c.file,
      sizes: chunkData.sizes
    });
  });

  return {
    assets,
    chunks,
    errors: [],
    warnings: [],
    modulesByChunkId: [],
    summary
  };
}

/* ------------------------------------------------------------------------------------------------------------------ */

interface ChunkData {
  id: string;
  name: string;
  file: string;
  sizes: SizeData;
}

interface SizeData {
  gzipped: number;
  parsed: number;
}

interface ModuleData {
  file: string;
  size: number;
  isDep: boolean;
}

function createSizeData(): SizeData {
  return { gzipped: 0, parsed: 0 };
}

function getChunkData(chunk: any): ChunkData {
  return {
    id: String(chunk.id),
    name: chunk.names[0],
    file: chunk.files[0],
    sizes: createSizeData()
  };
}

function parseSizeFromBuildOutput(s: string) {
  const matched = s.toLowerCase().match(/([\d.]+)\s*(kb|b|mb)/);
  if (matched) {
    const x = Number(matched[1]);
    switch (matched[2]) {
      case 'b':
        return x;
      case 'kb':
        return x * 1000;
      case 'mb':
        return x * 1000 * 1000;
      // Realistically assets should not be this big
      case 'gb':
        return x * 1000 * 1000 * 1000;
      default:
        return 0;
    }
  } else {
    return 0;
  }
}
